{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models import dist_model as dm\n",
    "from data import data_loader as dl\n",
    "import argparse\n",
    "from IPython import embed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from data.dataset.twoafc_dataset import TwoAFCDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "datasets = ['val/traditional','val/cnn','val/superres','val/deblur','val/color','val/frameinterp']\n",
    "dataset_mode = '2afc' # 2afc or jnd\n",
    "\n",
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grayscale models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional Baselines\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='L1',colorspace='Gray',use_gpu=is_cuda)\n",
    "m.model_name = 'L1 [LA]'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='L2',colorspace='Gray',use_gpu=is_cuda)\n",
    "m.model_name = 'L2 [LA]'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='ssim',colorspace='Gray',use_gpu=is_cuda)\n",
    "m.model_name = 'SSIM [LA]'\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watson models\n",
    "\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'gray_watson_dct_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='dct', colorspace='Gray',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-dct [LA]'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'gray_watson_fft_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='fft', colorspace='Gray',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-fft [LA]'\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watson vgg\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'gray_watson_vgg_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='vgg', colorspace='Gray',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-vgg [LA]'\n",
    "m.batch_size = m.batch_size // 4\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeploss competitor: not tuned vgg, all 5 layers even weight\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'gray_pnet_lin_vgg_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='net-lin', net='vgg', model_path=path, colorspace='Gray',use_gpu=is_cuda, batch_size=64)\n",
    "m.model_name = 'Deeploss-vgg [LA]'\n",
    "m.batch_size = m.batch_size // 4\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# color models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional Baselines\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='L1',colorspace='RGB',use_gpu=is_cuda)\n",
    "m.model_name = 'L1'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='L2',colorspace='RGB',use_gpu=is_cuda)\n",
    "m.model_name = 'L2'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='ssim',colorspace='RGB',use_gpu=is_cuda)\n",
    "m.model_name = 'SSIM'\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watson models\n",
    "\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'rgb_watson_dct_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='dct', colorspace='RGB',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-dct'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'rgb_watson_fft_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='fft', colorspace='RGB',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-fft'\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watson vgg\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'rgb_watson_vgg_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='vgg', colorspace='RGB',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-vgg'\n",
    "m.batch_size = m.batch_size // 4\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeploss competitor: not tuned vgg, all 5 layers even weight\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'rgb_pnet_lin_vgg_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='net-lin', net='vgg', model_path=path, colorspace='RGB',use_gpu=is_cuda, batch_size=64)\n",
    "m.model_name = 'Deeploss-vgg'\n",
    "m.batch_size = m.batch_size // 4\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddict(d):\n",
    "    return defaultdict(lambda: defaultdict(lambda: {}), d)\n",
    "\n",
    "def ddict2dict(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            d[k] = ddict2dict(v)\n",
    "    return dict(d)\n",
    "\n",
    "def dict2ddict(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            d[k] = dict2ddict(v)\n",
    "    return ddict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data loader\n",
    "def eval_loss_metric(model, resultdict=None):\n",
    "    if resultdict is None:\n",
    "        resultdict = defaultdict(lambda: defaultdict(lambda: {}))\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        \n",
    "        data_loader = dl.CreateDataLoader(dataset, dataset_mode=dataset_mode, batch_size=model.batch_size)\n",
    "\n",
    "        # evaluate model on data\n",
    "        if(dataset_mode=='2afc'):\n",
    "            (score, results_verbose) = dm.score_2afc_dataset(data_loader, model.forward)\n",
    "            resultdict[model.model_name][dataset]['score'] = results_verbose['scores'].mean()\n",
    "            resultdict[model.model_name][dataset]['std'] = results_verbose['scores'].std()\n",
    "            \n",
    "            human_judgements = results_verbose['gts']\n",
    "            human_scores = human_judgements**2 + (1 - human_judgements)**2\n",
    "            resultdict['Human'][dataset]['score'] = human_scores.mean()\n",
    "            resultdict['Human'][dataset]['std'] = human_scores.std()\n",
    "            \n",
    "            \n",
    "        elif(dataset_mode=='jnd'):\n",
    "            raise Exception('not implemented / validated')\n",
    "            (score, results_verbose) = dm.score_jnd_dataset(data_loader, model.forward)\n",
    "\n",
    "\n",
    "        # print results\n",
    "        print(' Model [%s]  Dataset [%s]: %.2f'%(model.model_name, dataset, 100.*score))\n",
    "    return resultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dict2ddict(pickle.load(open(\"eval_results.p\", \"rb\")))\n",
    "#res = defaultdict(lambda: defaultdict(lambda: {}))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print('eval model {} / {}: \"{}\"'.format(i+1, len(models), model.model_name))\n",
    "    eval_loss_metric(model, res)\n",
    "\n",
    "# save results\n",
    "pickle.dump(ddict2dict(res), open(\"eval_results.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT sensitivity vs phase weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../loss')\n",
    "from watson_fft_evaluating import WatsonDistanceFftEvaluating\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "datasets = ['val/traditional','val/cnn'] #,'val/superres','val/deblur','val/color','val/frameinterp']\n",
    "\n",
    "def eval_fft_amp_vs_phase_weighting(amp_factor, phase_factor):\n",
    "    # set up model\n",
    "    m = dm.DistModel()\n",
    "    path=os.path.join('./checkpoints/', 'gray_watson_fft_trial0', 'latest_net_.pth')\n",
    "    m.initialize(model='watson', net='fft', colorspace='Gray',use_gpu=is_cuda)\n",
    "    m.net.net = WatsonDistanceFftEvaluating(reduction = 'none')\n",
    "    m.net.load_state_dict(torch.load(path))\n",
    "    m.net.net.a = amp_factor\n",
    "    m.net.net.b = phase_factor\n",
    "    m.net = m.net.to(device)\n",
    "    \n",
    "    # eval\n",
    "    resultdict = eval_loss_metric(m)\n",
    "    score = sum([resultdict[m.model_name][d]['score'] for d in datasets]) / len(datasets)\n",
    "    error = sum([resultdict[m.model_name][d]['std'] for d in datasets]) / len(datasets)\n",
    "    \n",
    "    # get balance\n",
    "    amps = m.net.net.total_amplitude_term_dist\n",
    "    phase = m.net.net.total_phase_term_dist\n",
    "    \n",
    "    pct_amp = amps / (amps + phase)\n",
    "    pct_phase = phase / (amps + phase)\n",
    "    \n",
    "    return pct_amp, pct_phase, score, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb7b0c8cd7342a99eff94783008c7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steffen/study/VAE-perceptual-loss/venv-pytorch/lib/python3.5/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model [Watson]  Dataset [val/traditional]: 55.02\n",
      " Model [Watson]  Dataset [val/cnn]: 75.35\n",
      " Model [Watson]  Dataset [val/traditional]: 56.78\n",
      " Model [Watson]  Dataset [val/cnn]: 76.19\n",
      " Model [Watson]  Dataset [val/traditional]: 56.88\n",
      " Model [Watson]  Dataset [val/cnn]: 76.23\n",
      " Model [Watson]  Dataset [val/traditional]: 56.87\n",
      " Model [Watson]  Dataset [val/cnn]: 76.26\n",
      " Model [Watson]  Dataset [val/traditional]: 57.02\n",
      " Model [Watson]  Dataset [val/cnn]: 76.35\n",
      " Model [Watson]  Dataset [val/traditional]: 57.17\n",
      " Model [Watson]  Dataset [val/cnn]: 76.44\n",
      " Model [Watson]  Dataset [val/traditional]: 57.28\n",
      " Model [Watson]  Dataset [val/cnn]: 76.52\n",
      " Model [Watson]  Dataset [val/traditional]: 57.40\n",
      " Model [Watson]  Dataset [val/cnn]: 76.57\n",
      " Model [Watson]  Dataset [val/traditional]: 57.48\n",
      " Model [Watson]  Dataset [val/cnn]: 76.56\n",
      " Model [Watson]  Dataset [val/traditional]: 57.57\n",
      " Model [Watson]  Dataset [val/cnn]: 76.60\n",
      " Model [Watson]  Dataset [val/traditional]: 57.67\n",
      " Model [Watson]  Dataset [val/cnn]: 76.63\n",
      " Model [Watson]  Dataset [val/traditional]: 57.91\n",
      " Model [Watson]  Dataset [val/cnn]: 76.68\n",
      " Model [Watson]  Dataset [val/traditional]: 58.09\n",
      " Model [Watson]  Dataset [val/cnn]: 76.63\n",
      " Model [Watson]  Dataset [val/traditional]: 58.16\n",
      " Model [Watson]  Dataset [val/cnn]: 76.67\n",
      " Model [Watson]  Dataset [val/traditional]: 58.30\n",
      " Model [Watson]  Dataset [val/cnn]: 76.73\n",
      " Model [Watson]  Dataset [val/traditional]: 58.54\n",
      " Model [Watson]  Dataset [val/cnn]: 76.75\n",
      " Model [Watson]  Dataset [val/traditional]: 58.62\n",
      " Model [Watson]  Dataset [val/cnn]: 76.79\n",
      " Model [Watson]  Dataset [val/traditional]: 58.70\n",
      " Model [Watson]  Dataset [val/cnn]: 76.90\n",
      " Model [Watson]  Dataset [val/traditional]: 58.90\n",
      " Model [Watson]  Dataset [val/cnn]: 76.93\n",
      " Model [Watson]  Dataset [val/traditional]: 59.02\n",
      " Model [Watson]  Dataset [val/cnn]: 76.94\n",
      " Model [Watson]  Dataset [val/traditional]: 59.24\n",
      " Model [Watson]  Dataset [val/cnn]: 76.94\n",
      " Model [Watson]  Dataset [val/traditional]: 59.38\n",
      " Model [Watson]  Dataset [val/cnn]: 76.94\n",
      " Model [Watson]  Dataset [val/traditional]: 59.43\n",
      " Model [Watson]  Dataset [val/cnn]: 77.01\n",
      " Model [Watson]  Dataset [val/traditional]: 59.72\n",
      " Model [Watson]  Dataset [val/cnn]: 77.06\n",
      " Model [Watson]  Dataset [val/traditional]: 59.81\n",
      " Model [Watson]  Dataset [val/cnn]: 77.12\n",
      " Model [Watson]  Dataset [val/traditional]: 59.94\n",
      " Model [Watson]  Dataset [val/cnn]: 77.18\n",
      " Model [Watson]  Dataset [val/traditional]: 60.22\n",
      " Model [Watson]  Dataset [val/cnn]: 77.21\n",
      " Model [Watson]  Dataset [val/traditional]: 60.42\n",
      " Model [Watson]  Dataset [val/cnn]: 77.29\n",
      " Model [Watson]  Dataset [val/traditional]: 60.54\n",
      " Model [Watson]  Dataset [val/cnn]: 77.42\n",
      " Model [Watson]  Dataset [val/traditional]: 60.75\n",
      " Model [Watson]  Dataset [val/cnn]: 77.53\n",
      " Model [Watson]  Dataset [val/traditional]: 60.93\n",
      " Model [Watson]  Dataset [val/cnn]: 77.63\n",
      " Model [Watson]  Dataset [val/traditional]: 61.13\n",
      " Model [Watson]  Dataset [val/cnn]: 77.65\n",
      " Model [Watson]  Dataset [val/traditional]: 61.24\n",
      " Model [Watson]  Dataset [val/cnn]: 77.62\n",
      " Model [Watson]  Dataset [val/traditional]: 61.39\n",
      " Model [Watson]  Dataset [val/cnn]: 77.65\n",
      " Model [Watson]  Dataset [val/traditional]: 61.51\n",
      " Model [Watson]  Dataset [val/cnn]: 77.65\n",
      " Model [Watson]  Dataset [val/traditional]: 61.66\n",
      " Model [Watson]  Dataset [val/cnn]: 77.71\n",
      " Model [Watson]  Dataset [val/traditional]: 61.65\n",
      " Model [Watson]  Dataset [val/cnn]: 77.77\n",
      " Model [Watson]  Dataset [val/traditional]: 61.70\n",
      " Model [Watson]  Dataset [val/cnn]: 77.82\n",
      " Model [Watson]  Dataset [val/traditional]: 61.89\n",
      " Model [Watson]  Dataset [val/cnn]: 77.84\n",
      " Model [Watson]  Dataset [val/traditional]: 62.05\n",
      " Model [Watson]  Dataset [val/cnn]: 77.92\n",
      " Model [Watson]  Dataset [val/traditional]: 62.16\n",
      " Model [Watson]  Dataset [val/cnn]: 77.97\n",
      " Model [Watson]  Dataset [val/traditional]: 62.34\n",
      " Model [Watson]  Dataset [val/cnn]: 77.95\n",
      " Model [Watson]  Dataset [val/traditional]: 62.51\n",
      " Model [Watson]  Dataset [val/cnn]: 78.01\n",
      " Model [Watson]  Dataset [val/traditional]: 62.62\n",
      " Model [Watson]  Dataset [val/cnn]: 78.10\n",
      " Model [Watson]  Dataset [val/traditional]: 62.81\n",
      " Model [Watson]  Dataset [val/cnn]: 78.11\n",
      " Model [Watson]  Dataset [val/traditional]: 62.81\n",
      " Model [Watson]  Dataset [val/cnn]: 78.05\n",
      " Model [Watson]  Dataset [val/traditional]: 62.92\n",
      " Model [Watson]  Dataset [val/cnn]: 78.04\n",
      " Model [Watson]  Dataset [val/traditional]: 62.98\n",
      " Model [Watson]  Dataset [val/cnn]: 78.07\n",
      " Model [Watson]  Dataset [val/traditional]: 63.02\n",
      " Model [Watson]  Dataset [val/cnn]: 78.02\n",
      " Model [Watson]  Dataset [val/traditional]: 63.01\n",
      " Model [Watson]  Dataset [val/cnn]: 78.04\n",
      " Model [Watson]  Dataset [val/traditional]: 63.01\n",
      " Model [Watson]  Dataset [val/cnn]: 78.10\n",
      " Model [Watson]  Dataset [val/traditional]: 63.03\n",
      " Model [Watson]  Dataset [val/cnn]: 78.11\n",
      " Model [Watson]  Dataset [val/traditional]: 63.06\n",
      " Model [Watson]  Dataset [val/cnn]: 78.10\n",
      " Model [Watson]  Dataset [val/traditional]: 63.13\n",
      " Model [Watson]  Dataset [val/cnn]: 78.10\n",
      " Model [Watson]  Dataset [val/traditional]: 63.25\n",
      " Model [Watson]  Dataset [val/cnn]: 78.15\n",
      " Model [Watson]  Dataset [val/traditional]: 63.26\n",
      " Model [Watson]  Dataset [val/cnn]: 78.14\n",
      " Model [Watson]  Dataset [val/traditional]: 63.20\n",
      " Model [Watson]  Dataset [val/cnn]: 78.16\n",
      " Model [Watson]  Dataset [val/traditional]: 63.21\n",
      " Model [Watson]  Dataset [val/cnn]: 78.18\n",
      " Model [Watson]  Dataset [val/traditional]: 63.28\n",
      " Model [Watson]  Dataset [val/cnn]: 78.21\n",
      " Model [Watson]  Dataset [val/traditional]: 63.38\n",
      " Model [Watson]  Dataset [val/cnn]: 78.19\n",
      " Model [Watson]  Dataset [val/traditional]: 63.43\n",
      " Model [Watson]  Dataset [val/cnn]: 78.20\n",
      " Model [Watson]  Dataset [val/traditional]: 63.48\n",
      " Model [Watson]  Dataset [val/cnn]: 78.24\n",
      " Model [Watson]  Dataset [val/traditional]: 63.44\n",
      " Model [Watson]  Dataset [val/cnn]: 78.23\n",
      " Model [Watson]  Dataset [val/traditional]: 63.41\n",
      " Model [Watson]  Dataset [val/cnn]: 78.17\n",
      " Model [Watson]  Dataset [val/traditional]: 63.38\n",
      " Model [Watson]  Dataset [val/cnn]: 78.16\n",
      " Model [Watson]  Dataset [val/traditional]: 63.37\n",
      " Model [Watson]  Dataset [val/cnn]: 78.18\n",
      " Model [Watson]  Dataset [val/traditional]: 63.37\n",
      " Model [Watson]  Dataset [val/cnn]: 78.17\n",
      " Model [Watson]  Dataset [val/traditional]: 63.34\n",
      " Model [Watson]  Dataset [val/cnn]: 78.18\n",
      " Model [Watson]  Dataset [val/traditional]: 63.39\n",
      " Model [Watson]  Dataset [val/cnn]: 78.14\n",
      " Model [Watson]  Dataset [val/traditional]: 63.35\n",
      " Model [Watson]  Dataset [val/cnn]: 78.11\n",
      " Model [Watson]  Dataset [val/traditional]: 63.35\n",
      " Model [Watson]  Dataset [val/cnn]: 78.11\n",
      " Model [Watson]  Dataset [val/traditional]: 63.37\n",
      " Model [Watson]  Dataset [val/cnn]: 78.12\n",
      " Model [Watson]  Dataset [val/traditional]: 63.38\n",
      " Model [Watson]  Dataset [val/cnn]: 78.10\n",
      " Model [Watson]  Dataset [val/traditional]: 63.38\n",
      " Model [Watson]  Dataset [val/cnn]: 78.08\n",
      " Model [Watson]  Dataset [val/traditional]: 63.48\n",
      " Model [Watson]  Dataset [val/cnn]: 78.08\n",
      " Model [Watson]  Dataset [val/traditional]: 63.55\n",
      " Model [Watson]  Dataset [val/cnn]: 78.08\n",
      " Model [Watson]  Dataset [val/traditional]: 63.56\n",
      " Model [Watson]  Dataset [val/cnn]: 78.07\n",
      " Model [Watson]  Dataset [val/traditional]: 63.58\n",
      " Model [Watson]  Dataset [val/cnn]: 78.05\n",
      " Model [Watson]  Dataset [val/traditional]: 63.58\n",
      " Model [Watson]  Dataset [val/cnn]: 78.05\n",
      " Model [Watson]  Dataset [val/traditional]: 63.55\n",
      " Model [Watson]  Dataset [val/cnn]: 78.05\n",
      " Model [Watson]  Dataset [val/traditional]: 63.58\n",
      " Model [Watson]  Dataset [val/cnn]: 78.04\n",
      " Model [Watson]  Dataset [val/traditional]: 63.56\n",
      " Model [Watson]  Dataset [val/cnn]: 78.04\n",
      " Model [Watson]  Dataset [val/traditional]: 63.56\n",
      " Model [Watson]  Dataset [val/cnn]: 78.04\n",
      " Model [Watson]  Dataset [val/traditional]: 63.58\n",
      " Model [Watson]  Dataset [val/cnn]: 78.04\n",
      " Model [Watson]  Dataset [val/traditional]: 63.58\n",
      " Model [Watson]  Dataset [val/cnn]: 78.02\n",
      " Model [Watson]  Dataset [val/traditional]: 63.58\n",
      " Model [Watson]  Dataset [val/cnn]: 78.01\n",
      " Model [Watson]  Dataset [val/traditional]: 63.63\n",
      " Model [Watson]  Dataset [val/cnn]: 78.00\n",
      " Model [Watson]  Dataset [val/traditional]: 63.63\n",
      " Model [Watson]  Dataset [val/cnn]: 77.99\n",
      " Model [Watson]  Dataset [val/traditional]: 63.65\n",
      " Model [Watson]  Dataset [val/cnn]: 78.01\n",
      " Model [Watson]  Dataset [val/traditional]: 63.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model [Watson]  Dataset [val/cnn]: 78.01\n",
      " Model [Watson]  Dataset [val/traditional]: 63.63\n",
      " Model [Watson]  Dataset [val/cnn]: 78.03\n",
      " Model [Watson]  Dataset [val/traditional]: 63.63\n",
      " Model [Watson]  Dataset [val/cnn]: 78.05\n",
      " Model [Watson]  Dataset [val/traditional]: 63.67\n",
      " Model [Watson]  Dataset [val/cnn]: 78.05\n",
      " Model [Watson]  Dataset [val/traditional]: 63.66\n",
      " Model [Watson]  Dataset [val/cnn]: 78.07\n",
      " Model [Watson]  Dataset [val/traditional]: 63.66\n",
      " Model [Watson]  Dataset [val/cnn]: 78.07\n",
      " Model [Watson]  Dataset [val/traditional]: 63.66\n",
      " Model [Watson]  Dataset [val/cnn]: 78.07\n",
      " Model [Watson]  Dataset [val/traditional]: 63.67\n",
      " Model [Watson]  Dataset [val/cnn]: 78.07\n",
      " Model [Watson]  Dataset [val/traditional]: 63.67\n",
      " Model [Watson]  Dataset [val/cnn]: 78.07\n",
      " Model [Watson]  Dataset [val/traditional]: 63.67\n",
      " Model [Watson]  Dataset [val/cnn]: 78.07\n",
      " Model [Watson]  Dataset [val/traditional]: 63.66\n",
      " Model [Watson]  Dataset [val/cnn]: 78.06\n",
      " Model [Watson]  Dataset [val/traditional]: 63.66\n",
      " Model [Watson]  Dataset [val/cnn]: 78.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = [0] + list(np.logspace(-3, 0, num=100))\n",
    "res = {'frac_amps' : [], 'alpha':[], 'scores' : [], 'errors' : []}\n",
    "for a in tqdm(alphas):\n",
    "    pct_amp, pct_phase, score, error = eval_fft_amp_vs_phase_weighting(a, 1 - a)\n",
    "    res['frac_amps'].append(pct_amp)\n",
    "    res['alpha'].append(a)\n",
    "    res['scores'].append(score)\n",
    "    res['errors'].append(error)\n",
    "    \n",
    "pickle.dump(res, open(\"fft_amp_phase_weighting.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-pytorch",
   "language": "python",
   "name": "venv-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
