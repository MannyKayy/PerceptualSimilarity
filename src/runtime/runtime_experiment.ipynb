{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pmH4O5Ao7zIw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm as tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from IPython.core.debugger import set_trace\n",
    "import sys\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# load loss functions\n",
    "sys.path.append('../loss')\n",
    "from loss_provider import LossProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5L1yoc4o7zLY"
   },
   "outputs": [],
   "source": [
    "dataset_path = '../datasets/celebA/'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "data_dim = (3,64,64)\n",
    "data_size = np.prod(data_dim)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2JcRGGI7zNw"
   },
   "outputs": [],
   "source": [
    " \n",
    "# key word args for loading data\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == \"cuda\" else {}\n",
    "\n",
    "# transformers\n",
    "transformers = transforms.Compose([\n",
    "    transforms.ToTensor()                                # as tensors\n",
    "])\n",
    "transformers_la = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()                                # as tensors\n",
    "])\n",
    "\n",
    "data_set = datasets.ImageFolder(dataset_path, transform=transformers)\n",
    "data_set_la = datasets.ImageFolder(dataset_path, transform=transformers_la)\n",
    "\n",
    "\n",
    "# load datasets and make them easily fetchable in DataLoaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n",
    "data_loader_la = torch.utils.data.DataLoader(\n",
    "    data_set_la,\n",
    "    batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JRg19hermUJ9"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-yZmTOrkytU"
   },
   "outputs": [],
   "source": [
    "for data, lable in data_loader:\n",
    "    x = data\n",
    "    break\n",
    "    \n",
    "for data, lable in data_loader_la:\n",
    "    x_la = data\n",
    "    break\n",
    "    \n",
    "x = x.to(device)\n",
    "x_la = x_la.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ip1TGjxpZZcE"
   },
   "source": [
    "# We reconstruct an inut sample, for 500 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EaX9-lb1ZYmB"
   },
   "outputs": [],
   "source": [
    "class ReconSample(nn.Module):\n",
    "    def __init__(self, ground_truth, loss_function):\n",
    "        super().__init__()\n",
    "        self.loss = loss_function\n",
    "        self.recon = nn.Parameter(torch.randn(ground_truth.shape))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def get_recon(self):\n",
    "        return self.sigmoid(self.recon)\n",
    "    \n",
    "    def forward(self, ground_truth):\n",
    "        return self.loss(self.get_recon(), ground_truth)\n",
    "\n",
    "def runtime_test(x, loss_function, epochs=500):\n",
    "    reconstructor = ReconSample(x, loss_function)\n",
    "    reconstructor = reconstructor.to(device)\n",
    "    optimizer = torch.optim.SGD(reconstructor.parameters(), lr=10**-4)\n",
    "    \n",
    "    # train\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    mem0 =  torch.cuda.max_memory_allocated() \n",
    "    reconstructor.loss = reconstructor.loss.to(device)\n",
    "    t0 = time.time()\n",
    "    for iter in tqdm(range(epochs), leave=True, position=0):\n",
    "        optimizer.zero_grad()\n",
    "        loss = reconstructor.forward(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    t1 = time.time()\n",
    "    mem1 = torch.cuda.max_memory_allocated()\n",
    "        \n",
    "    return {'runtime':t1 - t0, 'memory':(mem1 - mem0) / (1024**2)}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test for each loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1049032,
     "status": "ok",
     "timestamp": 1573509066723,
     "user": {
      "displayName": "Steffen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAeU5QBgpn32R9Fl2b6Vslnm9tC5z9t6xsBFy8x=s64",
      "userId": "02457898349050092827"
     },
     "user_tz": -60
    },
    "id": "3pw6hKzTpWqP",
    "outputId": "6a82df10-7400-41ba-f5bb-1fad9b8c46ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 1529.55it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2431.09it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 125.67it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 41.09it/s]\n",
      "100%|██████████| 500/500 [00:13<00:00, 37.82it/s]\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:08<00:00, 68.4MB/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.28it/s]\n",
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\" to /root/.cache/torch/checkpoints/squeezenet1_1-f364aa15.pth\n",
      "100%|██████████| 4.74M/4.74M [00:00<00:00, 24.1MB/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 51.94it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2511.63it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2648.92it/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 97.34it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 143.77it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 136.24it/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.29it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 52.37it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2579.09it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2716.60it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 126.15it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 40.91it/s]\n",
      "100%|██████████| 500/500 [00:13<00:00, 38.38it/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.28it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 52.12it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2858.37it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2992.75it/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 97.35it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 143.80it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 136.33it/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.29it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 52.39it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2459.86it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2570.28it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 126.17it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 41.34it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 38.49it/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.29it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 52.14it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2924.93it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3197.29it/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 97.36it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 143.84it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 136.49it/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.29it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 52.40it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2620.34it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2898.20it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 126.17it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 41.30it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 38.55it/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.29it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 52.15it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2740.63it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2943.64it/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 97.36it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 143.90it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 136.44it/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.29it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 52.40it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2714.73it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2742.85it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 126.19it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 41.39it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 38.65it/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.29it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 52.16it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3209.31it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2727.21it/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 97.36it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 143.86it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 136.41it/s]\n",
      "100%|██████████| 500/500 [01:08<00:00,  7.29it/s]\n",
      "100%|██████████| 500/500 [00:09<00:00, 52.41it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_provider = LossProvider()\n",
    "results = {}\n",
    "for _ in range(5):\n",
    "    for color_model in ['RGB', 'LA']:\n",
    "        for loss_metric in loss_provider.loss_functions:\n",
    "            if loss_metric == 'Watson-vgg':\n",
    "                continue\n",
    "            key = loss_metric + ' ' + color_model\n",
    "            if key not in results:\n",
    "                results[key] = {}\n",
    "                results[key]['runtime'] = []\n",
    "                results[key]['memory'] = []\n",
    "            loss_function = loss_provider.get_loss_function(loss_metric, color_model)\n",
    "            data = x if color_model == 'RGB' else x_la\n",
    "            res =  runtime_test(data, loss_function, epochs=500)\n",
    "            results[key]['runtime'].append(res['runtime'])\n",
    "            results[key]['memory'].append(res['memory'])\n",
    "\n",
    "pickle.dump(results, open(os.path.join(g_drive_path, 'runtime_results_repitition.pickle'), 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1573509844177,
     "user": {
      "displayName": "Steffen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAeU5QBgpn32R9Fl2b6Vslnm9tC5z9t6xsBFy8x=s64",
      "userId": "02457898349050092827"
     },
     "user_tz": -60
    },
    "id": "anTHssq0HbAA",
    "outputId": "dc1dfc22-00ec-450c-b1fc-e42644741182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 RGB: runtime mean: 0.2212538242340088s, max memory 24.0009765625Mb\n",
      "L2 RGB: runtime mean: 0.18922247886657714s, max memory 24.0009765625Mb\n",
      "SSIM RGB: runtime mean: 3.9674572944641113s, max memory 114.00390625Mb\n",
      "Watson-dct RGB: runtime mean: 12.134006309509278s, max memory 96.00537109375Mb\n",
      "Watson-fft RGB: runtime mean: 13.034832668304443s, max memory 111.00830078125Mb\n",
      "Deeploss-vgg RGB: runtime mean: 68.31339735984803s, max memory 2213.69580078125Mb\n",
      "Deeploss-squeeze RGB: runtime mean: 9.598410892486573s, max memory 544.99609375Mb\n",
      "L1 LA: runtime mean: 0.177947473526001s, max memory 8.0009765625Mb\n",
      "L2 LA: runtime mean: 0.17431650161743165s, max memory 8.0009765625Mb\n",
      "SSIM LA: runtime mean: 5.137272596359253s, max memory 38.00244140625Mb\n",
      "Watson-dct LA: runtime mean: 3.4779707908630373s, max memory 35.0634765625Mb\n",
      "Watson-fft LA: runtime mean: 3.6676302909851075s, max memory 37.5029296875Mb\n",
      "Deeploss-vgg LA: runtime mean: 68.26854333877563s, max memory 2205.69580078125Mb\n",
      "Deeploss-squeeze LA: runtime mean: 9.544376134872437s, max memory 537.24609375Mb\n"
     ]
    }
   ],
   "source": [
    "for model in results:\n",
    "    print('{}: runtime mean: {}s, max memory {}Mb'.format(model, np.mean(results[model]['runtime']), max(results[model]['memory'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1573510043989,
     "user": {
      "displayName": "Steffen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAeU5QBgpn32R9Fl2b6Vslnm9tC5z9t6xsBFy8x=s64",
      "userId": "02457898349050092827"
     },
     "user_tz": -60
    },
    "id": "SjDICbA2gdC9",
    "outputId": "eb57033b-2bba-4986-efd5-fc215e0d9bbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(device=None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "runtime_experiment.ipynb",
   "provenance": [
    {
     "file_id": "1Q9z50CFyL3k6qCXztheIph7X1-CALf9x",
     "timestamp": 1567102025151
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv-perceptual-sim2",
   "language": "python",
   "name": "venv-perceptual-sim2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
