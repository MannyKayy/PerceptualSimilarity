{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# model\n",
    "#from reg_loss_vae_more_layers import RegLossVAE\n",
    "from celebA_vae import CelebAVAE\n",
    "\n",
    "# load loss functions\n",
    "import sys\n",
    "sys.path.append('./../../loss')\n",
    "from loss_provider import LossProvider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './../../datasets/celebA/images/'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "data_dim = (3,64,64)\n",
    "data_size = np.prod(data_dim)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key word args for loading data\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == \"cuda\" else {}\n",
    "\n",
    "dataset = datasets.ImageFolder(dataset_path, transform=transforms.ToTensor())\n",
    "data_size = len(dataset)\n",
    "train_size = int(0.9 * data_size)\n",
    "test_size = data_size - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# load datasets and make them easily fetchable in DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n",
    "\n",
    "# load datasets and make them easily fetchable in DataLoaders\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxillary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "to_img = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "idx = np.random.randint(0,len(test_set),8)\n",
    "sample_set = [test_set[i][0].numpy() for i in idx]\n",
    "sample_set = torch.tensor(sample_set, dtype=torch.float32)\n",
    "sample_set = sample_set.to(device)\n",
    "\n",
    "grid = torchvision.utils.make_grid(sample_set.cpu(), nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)\n",
    "print('reconstruction samples:')\n",
    "to_img(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_reconstruction(model, logger):\n",
    "    # plots reconstruction of a couple inputs\n",
    "    with torch.no_grad():\n",
    "        z, _ = model.encode(sample_set)\n",
    "        recon = model.decode(z)\n",
    "    comparison = torch.cat([sample_set[:8], recon[:8],sample_set[8:], recon[8:]])\n",
    "    torchvision.utils.save_image(comparison.cpu(),\n",
    "             logger.path + 'reconstruction_' + str(logger.minibatch) + '.png', nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpol_set = torch.cat([test_set[i][0].expand((1,) + data_dim) for i in range(3)])\n",
    "        \n",
    "interpol_set = torch.as_tensor(interpol_set, dtype=torch.float32)\n",
    "interpol_set = interpol_set.to(device)\n",
    "\n",
    "grid = torchvision.utils.make_grid(interpol_set.cpu(), nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)\n",
    "print('interpolation samples:')\n",
    "to_img(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_interpol(model, logger):\n",
    "    # plots interpolation of a couple inputs\n",
    "    with torch.no_grad():\n",
    "        N = 16\n",
    "        zs = model.encode(interpol_set)[0].detach().cpu().numpy()\n",
    "        if zs.shape[1] == 2:\n",
    "            # 2 dimensional latent space. Interpolate over entire latent space\n",
    "            z0 = np.array([-2., 2.])\n",
    "            z0to1 = np.array([4., 0.])\n",
    "            z0to2 = np.array([0., -4.])\n",
    "        else:\n",
    "            # multi-dimensional latent space. interpolate between samples\n",
    "            z0 = zs[0]\n",
    "            z0to1 = zs[1] - z0\n",
    "            z0to2 = zs[2] - z0\n",
    "        zs = []\n",
    "        for y in range(N):\n",
    "            for x in range(N):\n",
    "                zs.append(z0 + z0to1 * (x/(N-1)) + z0to2 * (y/(N-1)))\n",
    "        zs = torch.tensor(zs, dtype=torch.float32)\n",
    "        zs = zs.to(device)\n",
    "        recon = model.decode(zs)\n",
    "    torchvision.utils.save_image(recon.cpu(),\n",
    "             logger.path + 'interpol_' + str(logger.minibatch) + '.png', nrow=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_latents(model, n, epoch, logger):\n",
    "    # samples random values from latent space\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(n, model.latent_space).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        torchvision.utils.save_image(sample.view(n, data_dim[0], data_dim[1], data_dim[2]),\n",
    "                   logger.path + 'sample_' + str(logger.minibatch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(output_path):\n",
    "    model = torch.load(output_path + 'model.pckl')\n",
    "    logger = pickle.load(open(output_path + 'log.pckl', \"rb\"))\n",
    "    loss_fun = pickle.load(open(output_path + 'loss_fun.pckl', \"rb\"))\n",
    "    return logger, model, loss_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(logger, model, loss_fun):\n",
    "    torch.save(model, logger.path + 'model.pckl')\n",
    "    pickle.dump(logger, open(logger.path + 'log.pckl', \"wb\"))\n",
    "    pickle.dump(loss_fun, open(logger.path + 'loss_fun.pckl', \"wb\"))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger():\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.minibatch = 0\n",
    "        \n",
    "        # make output dir\n",
    "        if not os.path.isdir(self.path):\n",
    "            os.mkdir(self.path)\n",
    "        \n",
    "        stats = {}\n",
    "        for l in ['train', 'test']:\n",
    "            stats[l] = {'losses': [],\n",
    "                         'recon_losses': [],\n",
    "                         'recon_losses2': [],\n",
    "                         'kl_losses': [],\n",
    "                         'mean_z': [],\n",
    "                         'var_z': [],\n",
    "                         'var_mu': [],\n",
    "                         'idx': []}\n",
    "        self.stats = stats\n",
    "        return\n",
    "        \n",
    "    def train_step(self, kl_loss, recon_loss, recon_loss2, z, mu):\n",
    "        self.step('train', self.minibatch, kl_loss, recon_loss, recon_loss2, z, mu)\n",
    "        self.minibatch += 1\n",
    "        return\n",
    "        \n",
    "    def test_step(self, kl_loss, recon_loss, recon_loss2, z, mu):\n",
    "        return self.step('test', self.minibatch, kl_loss, recon_loss, recon_loss2, z, mu)\n",
    "    \n",
    "    def step(self, env, idx, kl_loss, recon_loss, recon_loss2, z, mu):\n",
    "        \"\"\"\n",
    "        logs one training step\n",
    "        \"\"\"\n",
    "        self.stats[env]['recon_losses'].append(recon_loss.item() / batch_size)\n",
    "        self.stats[env]['recon_losses2'].append(recon_loss2.item() / batch_size)\n",
    "        self.stats[env]['kl_losses'].append(kl_loss.item() / batch_size)\n",
    "        self.stats[env]['losses'].append(recon_loss.item() + kl_loss.item() / batch_size)\n",
    "        self.stats[env]['mean_z'].append(z.mean().item())\n",
    "        self.stats[env]['var_z'].append(z.var().item())\n",
    "        self.stats[env]['var_mu'].append(mu.var().item())\n",
    "        self.stats[env]['idx'].append(idx)\n",
    "        return\n",
    "    \n",
    "    def plot(self):\n",
    "        if 2 >= len(self.stats['train']['losses']):\n",
    "            print('need at least 2 epochs of data for plot')\n",
    "            return\n",
    "        xs_train = self.stats['train']['idx']\n",
    "        xs_test = self.stats['test']['idx']\n",
    "\n",
    "        # Two subplots, unpack the axes array immediately\n",
    "        f, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=True, figsize=(6,8))\n",
    "        ax1.semilogy(xs_train, self.stats['train']['recon_losses'], label='train')\n",
    "        ax1.semilogy(xs_test, self.stats['test']['recon_losses'], label='test')\n",
    "        ax1.set_ylabel('$\\mathcal{L}_{rec}$')\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        ax2.plot(xs_train, self.stats['train']['mean_z'])\n",
    "        ax2.plot(xs_test, self.stats['test']['mean_z'])\n",
    "        ax2.set_ylabel('$\\mu(z)$')\n",
    "        ax3.plot(xs_train, self.stats['train']['var_z'])\n",
    "        ax3.plot(xs_test, self.stats['test']['var_z'])\n",
    "        ax3.set_ylabel('$\\sigma^2(z)$')\n",
    "        ax4.plot(xs_train, np.array(self.stats['train']['var_z']) - np.array(self.stats['train']['var_mu']))\n",
    "        ax4.plot(xs_test, np.array(self.stats['test']['var_z']) - np.array(self.stats['test']['var_mu']))\n",
    "        ax4.set_xlabel('Minibatch')\n",
    "        ax4.set_ylabel('$\\sigma^2(z) - \\sigma^2(\\mu(X))$')\n",
    "        f.savefig(self.path + 'training.pdf')\n",
    "        plt.close(fig=f)\n",
    "        return\n",
    "    \n",
    "    def plot_loss_comparison(self):\n",
    "        if 2 >= len(self.stats['train']['losses']):\n",
    "            # print('need at least 2 epochs of data for plot')\n",
    "            return\n",
    "        xs_train = self.stats['train']['idx']\n",
    "        xs_test = self.stats['test']['idx']\n",
    "        f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(6,6))\n",
    "        ax1.semilogy(xs_train, self.stats['train']['recon_losses'], label='train')\n",
    "        ax1.semilogy(xs_test, self.stats['test']['recon_losses'], label='test')\n",
    "        ax1.set_ylabel('$\\mathcal{L}_{rec}$ of training objective')\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "        ax2.semilogy(xs_train, self.stats['train']['recon_losses2'], label='train')\n",
    "        ax2.semilogy(xs_test, self.stats['test']['recon_losses2'], label='test')\n",
    "        ax2.set_ylabel('other $\\mathcal{L}_{rec}$ metric')\n",
    "        ax2.set_xlabel('Minibatch')\n",
    "        f.savefig(self.path + 'comparison.pdf')\n",
    "        plt.close(fig=f)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KL-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization_loss(mu, logvar):\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2), sum is over all dim of the latent distribution z\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(epoch, model, train_set, loss_fun, loss_fun_comparison, lam, optimizer, logger): # train for one epoch\n",
    "    # set model to training mode, affects eg. dropout layers\n",
    "    model.train() \n",
    "    \n",
    "    for (data, _label) in train_set: # iterate over minibacthes\n",
    "        data = data.to(device) # cast data to gpu\n",
    "        optimizer.zero_grad() # set gradients to 0\n",
    "\n",
    "        recon_batch, mu, logvar, z = model(data) # run model\n",
    "        \n",
    "        # calculate loss\n",
    "        reconstruct_loss = lam * loss_fun(recon_batch, data)\n",
    "        kl_loss = regularization_loss(mu, logvar)\n",
    "        loss = reconstruct_loss + kl_loss\n",
    "        \n",
    "        if loss_fun_comparison is None:\n",
    "            reconstruct_loss2 = torch.tensor([0.])\n",
    "        else:\n",
    "            reconstruct_loss2 = lam * loss_fun_comparison(data, recon_batch)\n",
    "        \n",
    "        # propagate loss\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        \n",
    "        \n",
    "        # log\n",
    "        logger.train_step(kl_loss, reconstruct_loss, reconstruct_loss2, z, mu)\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(epoch, model, test_set, loss_fun, loss_fun_comparison, lam, logger): # train for one epoch\n",
    "    # set model to eval mode, affects eg. dropout layers\n",
    "    model.eval() \n",
    "    losses = [] \n"
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _label in test_set: # iterate over minibacthes\n",
    "            data = data.to(device) # cast data to gpu\n",
    "            recon_batch, mu, logvar, z = model(data) # run model\n",
    "\n",
    "            # calculate loss\n",
    "            reconstruct_loss = lam * loss_fun(recon_batch, data)\n",
    "            kl_loss = regularization_loss(mu, logvar)\n",
    "            loss = reconstruct_loss + kl_loss\n",
    "            \n",
    "            if loss_fun_comparison is None:\n",
    "                reconstruct_loss2 = torch.tensor([0.])\n",
    "            else:\n",
    "                reconstruct_loss2 = lam * loss_fun_comparison(data, recon_batch)\n",
    "\n",
    "            # log\n",
    "            logger.test_step(kl_loss, reconstruct_loss, reconstruct_loss2, z, mu)\n",
    "            losses.append(loss.item())\n",
    "                \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, initial_lr, lr_decline=(0.5 ** (1/20))):\n",
    "    \"\"\"declines the learning rate by a factor of $\\sqrt{20}{0.5}$ ever epoch, a reduction by half over every 20 epochs\"\"\"\n",
    "    lr = initial_lr * lr_decline**epoch\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_set, test_set, loss_fun, loss_fun_comparison=None, lam=1, epochs=10, initial_lr=5e-4,  logger=Logger('./results/')):\n",
    "    model = model.to(device)\n",
    "    loss_fun = loss_fun.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr)\n",
    "    lowest_loss = 999999999999\n",
    "    \n",
    "    # train\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        adjust_learning_rate(optimizer, epoch, initial_lr)\n",
    "        logger.plot()\n",
    "        if not(loss_fun_comparison is None):\n",
    "            logger.plot_loss_comparison()\n",
    "\n",
    "        train_step(epoch, model, train_set, loss_fun, loss_fun_comparison, lam, optimizer, logger)\n",
    "        \n",
    "        loss = test_step(epoch, model, test_set, loss_fun, loss_fun_comparison, lam, logger)\n",
    "\n",
    "        #clear_output()\n",
    "        sample_latents(model, 64, epoch, logger)\n",
    "        sample_interpol(model, logger)\n",
    "        sample_reconstruction(model, logger)\n",
    "        \n",
    "        \n",
    "            \n",
    "        # checkpoint\n",
    "        if loss < lowest_loss:\n",
    "            lowest_loss = loss\n",
    "            save_model(logger, model, loss_fun)\n",
    "            \n",
    "    return logger, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = LossProvider()\n",
    "print('available modes: {}'.format(provider.color_models))\n",
    "print('available loss functions: {}'.format(provider.loss_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains l2 loss comparison\n",
    "for loss_name, lam, pretrained in [('ssim', 12, True), ('watson-fft', 1, True), ('deeploss-vgg', 10, True), ('deeploss-squeeze', 9, True), ('adaptive', 2, False)]:\n",
    "    print('evaluating function {} with lambda e^{}'.format(loss_name, lam))\n",
    "    model = CelebAVAE(latent_space=256, input_size=data_dim)\n",
    "    loss_fun = provider.get_loss_function(loss_name, 'RGB', deterministic=False, pretrained=pretrained)\n",
    "    train_model(model=model, \n",
    "                        train_set=train_loader, \n",
    "                        test_set=test_loader, \n",
    "                        loss_fun=loss_fun,\n",
    "                        loss_fun_comparison=None,\n",
    "                        lam=np.exp(lam),\n",
    "                        epochs=100,\n",
    "                        initial_lr=1e-4,\n",
    "                        logger=Logger('./results/' + loss_name + '_lam_e'+str(lam)+'/')\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
